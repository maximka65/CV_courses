{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCdGFvtyItIK"
   },
   "source": [
    "# GAN overriding `Model.train_step`\n",
    "\n",
    "(https://twitter.com/fchollet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZn7_uCAItIM"
   },
   "source": [
    "## Загрузка модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPbdfnz4ItIO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eL0jLVLItIV"
   },
   "source": [
    "## строим Fashion_MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_5cxeh_ItIW",
    "outputId": "4cf28e8f-db6b-4886-bbe2-2d0f9ab38ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# MNIST \n",
    "batch_size = 64\n",
    "(x_train, _), (x_test, _) = keras.datasets.fashion_mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\") / 255\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9GINZz5ItIb"
   },
   "source": [
    "## Строим discriminator\n",
    "\n",
    "размер карты 28x28 и бинарная классификация (настоящее изображение или генерировано)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K99eZdkgItIc",
    "outputId": "cafb0d79-8750-46da-b716-885c4169e72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 74,625\n",
      "Trainable params: 74,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eodbCQ1WItIh"
   },
   "source": [
    "## Строим generator\n",
    "\n",
    "обратное по отношению к дискриминатору преобразование, меняем `Conv2D` на `Conv2DTranspose` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PY5lCMxqItIi",
    "outputId": "22c3f007-44f4-4b22-9158-d2010f0e9a2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              809088    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         12545     \n",
      "=================================================================\n",
      "Total params: 1,608,449\n",
      "Trainable params: 1,608,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        # строим размер входного вектора 7x7x128 map\n",
    "        layers.Dense(7 * 7 * 128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpX7dJvAItIn"
   },
   "source": [
    "## Класс со своим этапом обучения `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHP6aHUfItIo"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "        # берем случайный пример из скрытого пространства\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Строим по нему фейковое изображение\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # собрали с реальным в текзор\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # задаем метки 1 и 0 соответственно\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Добавляем шум !!!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # учим discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        #Выбрали случайный пример в скрытом пространстве\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # собрали метки реальных изображений\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Учим generator !\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4rYDb3qItIs"
   },
   "source": [
    "## Callback для сохранения изображений по ходу обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoLCvAe7ItIt"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiMWOk1_ItIz"
   },
   "source": [
    "## Учим end-to-end модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZSj0hUHItI0",
    "outputId": "1ae44ffe-3762-47bc-85dc-561b0eaf4177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1094/1094 [==============================] - 49s 37ms/step - d_loss: 0.4380 - g_loss: 2.9592\n",
      "Epoch 2/3\n",
      "1094/1094 [==============================] - 41s 38ms/step - d_loss: 0.2682 - g_loss: 2.4220\n",
      "Epoch 3/3\n",
      "1094/1094 [==============================] - 42s 38ms/step - d_loss: 0.1093 - g_loss: 3.3169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efc800b2940>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idate_fObUtI",
    "outputId": "0dc1b389-2b00-4c30-8a3c-197d7001d699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1094/1094 [==============================] - 42s 38ms/step - d_loss: 0.0520 - g_loss: 4.2551\n",
      "Epoch 2/3\n",
      "1094/1094 [==============================] - 42s 39ms/step - d_loss: 0.6807 - g_loss: 1.3616\n",
      "Epoch 3/3\n",
      "1094/1094 [==============================] - 42s 39ms/step - d_loss: 0.7317 - g_loss: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efc8003a6d8>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKqdR6bOItI4"
   },
   "source": [
    "Display the last generated images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "zZa20XZYItI5",
    "outputId": "84efaad1-be8d-46c3-c926-644887fab500"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACq0lEQVR4nF2SS0wTYRDH59t+7fa9bF9QWioIFFBaaCASowcPGAImGg8mmmg8GKMcNSZ6MjEmejAcvHjwZDQx8Wo8oIki8pCEViSFtID0QSmUUuhz+9rufh6KgMzx98tkJjN/BAfF1BeLGg7tQn4P4AMnf9wjD+d9pcCPfwTtO9mwlVqxBs2d/c9Hjkh06gUnUZH0mqA9bW6JVSG1J9vPsiydWY+msPvV1k/pfzPpviZ+dwmXWDqiyAXJ4MdDUkrF8782SZbatmmNMR81fqgTDXQJskA5I8qbOaYsD40x6eoilAiIGWHnYysmg0SmCedMWq2ae0gAALBGxypcWlmBbm3NGxfUxVKF0fG1mAcAwKhBZq/UedLZdk1oPSeTcyfE+DxCuIIwg7HZNKuf9eqPr1KM5k85mfQb6tRGF86krs3gnfEE5j3JJ5ppqv+LzxbzeI13K9LLk8s6OkSRFK4oVJKe7uYLWovWwKESKA0Gex8fe7uBoQhQ0GwvSGk27KUUZQHocmYBLWZJhlAAAKKvPMlNzEXsa4Vup82C1Ka2W5RIqkcgAvATemF3jreYdpu61FS+XKT2L2Q9c3/Z17dhnHHEB8NWiVrJNtaHSPUrWK67LYlzbxRbjNu7Gg2HVYtLeQDAgOQdA1knMbnSJ12rlKomV3CKvLszQwAwWF66RpHN6Y7MSt6JU8Ug8iitgYRftykChmNt8auCYYy+VNiKtdd8N+u5lo7z/kRcBEAgrdWNw8bwkONrxNFq9fy207z03PsP6wBAwdOpG6/7P2mv6Bm7I5eQ05vFuuizb9FqwBoejH4WJfcsFwPK+pmVISGGG803p3eqSUg8KgAIveV6ImMbVSop0WtwOLkXkwIAANzpvb7D5IPTXIqdVEf84pFQ61VZIY+AEACRVNFfgZIbcMfAMF8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACRklEQVR4nGNgoBJgxMFjZFYy57rMduXzT7gQC5xVWc7x7Odmvl9ver+g62Rx2MLy+LTC4zciGnum3UTTKVv5Yc2nt4KfrnFwfwmc/f4fkiRXtzf30XPvP0vx/r/14DU7r+gt5t8wY7mfs79fd+i5GAfv6y9PeX/Jf1ThXPLmHwMDI9t/rYQA/i+HH5l++qHE8mTNM25l/iMqsoI7Fa7sZ/HSMNe8d/vnyz0SDvMuyL46yKtpePzcY1HrfoEfiizFSpy3ntxj5lH/9eje/V8Sv75fZpEz5BPl/t0axMg05dHNp9c+/VE2OLyE48+7h/yP7u/+9P6n8IM91zhlWH48U/ig8OnXi0CTb4f/Bf/6VMsurXNXxOg7t+DlfyzHfv2ROOX4nk9SZOsLpvd/Z37+8Pa9jJXs0e+8vN8ZuUQFed8oMDMJX+KW1fyjcllg3y91yT/sEjdfas5i+cv9TesjA6sC99tXag/l1CQuJl2R/XTfTPSrGstnRlFNyx/CGjL37yvz6r+VZ3vwWvwpzzs+Ma7b0r9NWf6bad64rPRpzhPfiNQ/5j6TPQSlFn12Yl0i+OPrNxZBI57vfHPVeXU5vwn9vrXimMgt05+KBwO8WzveMjD9dmYJFTXn9TGKeifPLLiZj8diGcc76U/feb78YWDgOfFs/+0Xf6a//vvv+O//3+Z8+fX2wpc/3zbZQGJSVWnup0+G2y4ss37+94v9mYe7dBef1YPG5wedv8Vb1Q3sX++7YvOa4c+hlWyvrsf/IzYNUh0AACVKArJX6NAjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAChklEQVR4nGWSTUzTcBjG339b1nWD0W6jAqOwwZRvEIMRISEKkXhQCPFooidj9AoXryZ60YOaeNKYcBO9mYioCKhksoAKLESWMWDjaxvdWKHbuq1dPUyY4nN53zy/2y8PglysKTyEpL8KlHuJ50ni/f68ElIPmxwbaHzq2MO6es1d/8OXdmQnUrUspx18eBTSJxfT9ibjOvoSuS0/OgIHVHU2pqsJRvrXPH2GuwAAgP1hGiw4jYUxpgZPfH1GydkSI7O3sn6Frq7DvYhW7ay7T5OFPSUAAFDBzG9Iu/pSPUfG6fVydxEAIIzp1AMAajGK2l1UIE5MqG3NpSJ/g9RbuolPpIRUgLBbY1ta9ml/+El8SzO+0HrLzPsJRYsrANDLeqxtWCKp0QK33YSZjCC0LxKBoAoAaiVkzJaLEjf7uLwjXagRx8+ZuQABWZMm0FuS7C7BtTSQpoCB7FlfHf51IGFHqq0e9kk2cc3prCKLlwxburnMARRgiBlCPiZFO+R9SqLqVh2ZQ32bodSGEqU42dQesZBEvng1tHkILwgf+8sm/Y0ZMsFSwnGeYcw5t90htiQSjyeL8gttGqdLXHDaATDAAQDySqJ6r66/g0rzewkrsTJOeb8DEOjaSBAwe+/orC00jSWEIOavr4rK3st1Y0BgMVP47JXra9yZE2ScKgjg0SbdqfTpAPsGACGdLE8uj/4c5Lk5MdIRHCktJ9hO9wtXJgmImXl775g73/Z6K+wxLRVXfMOZZod3eyoFAIh88O6DAuASGp6QVindgPvzyioueXgAAEJ5NQUAUJxHnfdYeJNKx1iDwTrzz6iNN+/7wslY/POYrLY23lGOLJ6lgd4RohnI5TfsN/6Z2xhXVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\"generated_img_0_2.png\"))\n",
    "display(Image(\"generated_img_1_2.png\"))\n",
    "display(Image(\"generated_img_2_2.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "WruOaC0ahMZr",
    "outputId": "ac14043b-2b83-4a36-f7d3-48dd2eb9c7a2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACYklEQVR4nLXSzU/TcBzH8e+v/bXd1m1d28GgMDsmTOPAIBEPIBoJeDAL3ownoyTq3+FBEy/GxJvRePLpZmKMJnBQovgYDRKmxM3hxjLcurF1Y+v66EUNF7z5ub3zub4A/vsIhLcVI2+v8IAsUhRGAABASs9a3r8vOXBBr67kYkfvNrQs2X1d7Ma7MQAQIFpj/ul497vx7Kl08mzvA3Umtpz0TyG+f9b6wFQGRny9tCc7f45Y58i2trW/gKxZYl94Qh+qTPYGVUVPzb1vrubrtXRGIHxUCeF4TDiZAylXkEJkOhNb/CIGbCSwtOq18ljP13ySWFNMd5OHeFB3jR1ov2AFPVx5xOFdU25PFaC8xa2OGdHg2wjbKItex9Xy5St4gTdYof5GizxfGBwsR1VnPhICQSM0Mqni7LpcVL/eDxtZN0khFxTraz25iE+r2j0ZQjM9w67yp/7SsD28oroD9+ZeetY4xpRFopPo5Pci6Yb99LQw2uDkRlJgqVRFBR8Je0y8upjYWKjAtzuvxpcee88XPm9FcptIJZftAMZmtnm5BGA8pANGz3Fe73LcmqZ7TWVz5jY2i7OqAkA6Ixc70rJ0pujmj/XzLTRdEvwYtKxlA/joUUVxb/CFRGroo76iDLIENAinZVgAoIVf43X7ScPVNxmlGZ2utitUFIODAAC4wyfC7agkMDbFTGRCUovkCBkDOAAALqXhPWQxNLZtqq+LNDBdd0LEbwgHr3DXbhqWXqulmkvtEtKR31xDf5h0lhxg4/GfzI/v2tCRRJC1xUs7QMSB6K3yVbTDCwAd5D8d/wK8w/wLx7Be+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACSElEQVR4nF2RyW7TUBSGz/UUD6ljt27spDRKQ2kFAoq6KxtUCYFYwRKWLOEBkPoK8AxlDQ/ABgESEqIDIKQOgpaWCuiY1HFiO9fO9XBZtGkMZ3k+ff9/dC+C/4eRVd+jAACATlccNSAUruersyW8sv/MPVmeQtW8OR9WZm/fY0nj/cOrH7KQW4k/vkUvDl9Vrr1slG8s/1P0OIrrez8Onq+vxs7OEvG4bGf5l4Pp3mLxDog8YNarkUzsXMLpxFImiAuGaCeS9TtjzrwO6qvl1eMhU7DUo3Fm6jhjzktR05LPO9qWmAyreWYsA81xhk5Q0EN7wcK1MMpNfQIAYAAAoMrHm260feTz6dqXxZ1AegJ9uOF3c8z3hNW/qnxnTRTByzwCkqJKZDFElEppx8Fsx8yYSwzFTS4OYiPXEAeYAA1lTIUeRfxPBqiAZeNcO+L4QvvMTOrEt9cTSTC0yYrusTGW+rGaBKP8pZIcdgUF77munTzqQ7kre0mL1p0GdXV5wPG5u2edCPF/UDKS2qkqmZxL+A7P9g9KP6uEj1mL8b3iYMuWKamexZZopVA4kL3ICb7JZH+3vUllqQdTpmAICkkQjWEXV02hFiRPe/AWUuO2yoV+2sAW1xIDlI8u9zqHOwuTbs7WYkprmlKintEaRL3PfjdcBHwgYK3ebV7pcmR7rFA+njgxkSHxvgzNtABdukWKUXKohRqiwAAAt4xDL/DlKKdfnJ65UFHbFWUnHDiJzU1Oj021VxhF7xRH8hjW35ij4f0HG/AXlE4Fz/X1K4MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAChklEQVR4nGWSTUzTcBjG339b1nWD0W6jAqOwwZRvEIMRISEKkXhQCPFooidj9AoXryZ60YOaeNKYcBO9mYioCKhksoAKLESWMWDjaxvdWKHbuq1dPUyY4nN53zy/2y8PglysKTyEpL8KlHuJ50ni/f68ElIPmxwbaHzq2MO6es1d/8OXdmQnUrUspx18eBTSJxfT9ibjOvoSuS0/OgIHVHU2pqsJRvrXPH2GuwAAgP1hGiw4jYUxpgZPfH1GydkSI7O3sn6Frq7DvYhW7ay7T5OFPSUAAFDBzG9Iu/pSPUfG6fVydxEAIIzp1AMAajGK2l1UIE5MqG3NpSJ/g9RbuolPpIRUgLBbY1ta9ml/+El8SzO+0HrLzPsJRYsrANDLeqxtWCKp0QK33YSZjCC0LxKBoAoAaiVkzJaLEjf7uLwjXagRx8+ZuQABWZMm0FuS7C7BtTSQpoCB7FlfHf51IGFHqq0e9kk2cc3prCKLlwxburnMARRgiBlCPiZFO+R9SqLqVh2ZQ32bodSGEqU42dQesZBEvng1tHkILwgf+8sm/Y0ZMsFSwnGeYcw5t90htiQSjyeL8gttGqdLXHDaATDAAQDySqJ6r66/g0rzewkrsTJOeb8DEOjaSBAwe+/orC00jSWEIOavr4rK3st1Y0BgMVP47JXra9yZE2ScKgjg0SbdqfTpAPsGACGdLE8uj/4c5Lk5MdIRHCktJ9hO9wtXJgmImXl775g73/Z6K+wxLRVXfMOZZod3eyoFAIh88O6DAuASGp6QVindgPvzyioueXgAAEJ5NQUAUJxHnfdYeJNKx1iDwTrzz6iNN+/7wslY/POYrLY23lGOLJ6lgd4RohnI5TfsN/6Z2xhXVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(\"generated_img_2_0.png\"))\n",
    "display(Image(\"generated_img_2_1.png\"))\n",
    "display(Image(\"generated_img_2_2.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-o1cIfLhXhq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

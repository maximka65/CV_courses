{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попрактикуемся с тем, что изучили¶\n",
    "Будем практиковаться на датасете: https://www.kaggle.com/c/avito-demand-prediction\n",
    "\n",
    "Ваша задача:\n",
    "\n",
    "Создать Dataset для загрузки данных (используем только числовые данные)\n",
    "Обернуть его в Dataloader\n",
    "Написать архитектуру сети, которая предсказывает число показов на основании числовых данных (вы всегда можете нагенерить дополнительных факторов). Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
    "Учить будем на функцию потерь с кагла (log RMSE) - нужно её реализовать\n",
    "Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
    "train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25\n",
    "\n",
    "Вопросы? в личку @Kinetikm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from hw_03 import AvitoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data2/tran.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>Свердловская область</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>Private</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.12789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>Самарская область</td>\n",
       "      <td>Самара</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Private</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id                region          city  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9  Свердловская область  Екатеринбург   \n",
       "1  2dac0150717d  39aeb48f0017     Самарская область        Самара   \n",
       "\n",
       "  parent_category_name               category_name                    param_1  \\\n",
       "0          Личные вещи  Товары для детей и игрушки  Постельные принадлежности   \n",
       "1      Для дома и дачи           Мебель и интерьер                     Другое   \n",
       "\n",
       "  param_2 param_3                  title  \\\n",
       "0     NaN     NaN  Кокоби(кокон для сна)   \n",
       "1     NaN     NaN      Стойка для Одежды   \n",
       "\n",
       "                                         description   price  item_seq_number  \\\n",
       "0  Кокон для сна малыша,пользовались меньше месяц...   400.0                2   \n",
       "1          Стойка для одежды, под вешалки. С бутика.  3000.0               19   \n",
       "\n",
       "  activation_date user_type  \\\n",
       "0      2017-03-28   Private   \n",
       "1      2017-03-26   Private   \n",
       "\n",
       "                                               image  image_top_1  \\\n",
       "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...       1008.0   \n",
       "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...        692.0   \n",
       "\n",
       "   deal_probability  \n",
       "0           0.12789  \n",
       "1           0.00000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['price', 'item_seq_number', 'image_top_1', 'deal_probability']]\n",
    "data = data.loc[~data['price'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class AvitoData записал в отдельны Файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AvitoData(torch.utils.data.Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.data.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.data.iloc[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['price', 'item_seq_number', 'image_top_1']]\n",
    "y = data['deal_probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-8eb665eb7bc4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['y'] = y_train\n"
     ]
    }
   ],
   "source": [
    "train = X_train\n",
    "train['y'] = y_train\n",
    "test = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AvitoData(np.array(train))\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=1000, shuffle=True, num_workers=3, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.activation==\"relu\":\n",
    "            return F.relu(x)\n",
    "        if self.activation==\"sigmoid\":\n",
    "            return F.sigmoid(x)\n",
    "        #если ни одна не сработает\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout является методом решения проблемы переобучения, то что обычно происходит в глубоких нейронных сетях, тут же унас маленькая\n",
    "сетка с небольшим уровнем нелинейности, ей бы хоть какие-то закономерности уловить)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
    "        self.fc1 = Perceptron(input_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = Perceptron(hidden_dim, 10, \"relu\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(3, 10)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9682f61d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maximcucer/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/maximcucer/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1291, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   301] loss: 1.018\n",
      "[1,   601] loss: 0.356\n",
      "[1,   901] loss: 0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:32<04:53, 32.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.001\n",
      "[2,   301] loss: 0.200\n",
      "[2,   601] loss: 0.186\n",
      "[2,   901] loss: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [01:05<04:20, 32.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,     1] loss: 0.001\n",
      "[3,   301] loss: 0.177\n",
      "[3,   601] loss: 0.177\n",
      "[3,   901] loss: 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [01:36<03:46, 32.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,     1] loss: 0.001\n",
      "[4,   301] loss: 0.176\n",
      "[4,   601] loss: 0.176\n",
      "[4,   901] loss: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [02:08<03:13, 32.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,     1] loss: 0.001\n",
      "[5,   301] loss: 0.177\n",
      "[5,   601] loss: 0.176\n",
      "[5,   901] loss: 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [02:35<02:32, 30.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,     1] loss: 0.001\n",
      "[6,   301] loss: 0.176\n",
      "[6,   601] loss: 0.174\n",
      "[6,   901] loss: 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [03:04<02:00, 30.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,     1] loss: 0.001\n",
      "[7,   301] loss: 0.175\n",
      "[7,   601] loss: 0.178\n",
      "[7,   901] loss: 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [03:31<01:27, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,     1] loss: 0.001\n",
      "[8,   301] loss: 0.174\n",
      "[8,   601] loss: 0.178\n",
      "[8,   901] loss: 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [03:58<00:57, 28.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,     1] loss: 0.001\n",
      "[9,   301] loss: 0.174\n",
      "[9,   601] loss: 0.178\n",
      "[9,   901] loss: 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [04:27<00:28, 28.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,     1] loss: 0.001\n",
      "[10,   301] loss: 0.177\n",
      "[10,   601] loss: 0.175\n",
      "[10,   901] loss: 0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:55<00:00, 29.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(10)):  \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for i, data1 in enumerate(train_loader, 0):\n",
    "        data1 = pd.DataFrame(np.array(data1))\n",
    "        data1.dropna()\n",
    "        inputs = torch.tensor(np.array(data1[[0, 1, 2]])).type(torch.LongTensor)\n",
    "        labels = torch.tensor(np.array(data1[3])).type(torch.LongTensor)\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Net(3, 10)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = net2.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.008\n",
      "[1,   301] loss: 2.367\n",
      "[1,   601] loss: 2.367\n",
      "[1,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:42<06:20, 42.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.008\n",
      "[2,   301] loss: 2.367\n",
      "[2,   601] loss: 2.368\n",
      "[2,   901] loss: 2.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [01:07<04:57, 37.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,     1] loss: 0.008\n",
      "[3,   301] loss: 2.368\n",
      "[3,   601] loss: 2.368\n",
      "[3,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [01:32<03:55, 33.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,     1] loss: 0.008\n",
      "[4,   301] loss: 2.368\n",
      "[4,   601] loss: 2.367\n",
      "[4,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [01:59<03:08, 31.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,     1] loss: 0.008\n",
      "[5,   301] loss: 2.368\n",
      "[5,   601] loss: 2.368\n",
      "[5,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [02:25<02:28, 29.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,     1] loss: 0.008\n",
      "[6,   301] loss: 2.367\n",
      "[6,   601] loss: 2.368\n",
      "[6,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [02:50<01:54, 28.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,     1] loss: 0.008\n",
      "[7,   301] loss: 2.368\n",
      "[7,   601] loss: 2.367\n",
      "[7,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [03:15<01:21, 27.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,     1] loss: 0.008\n",
      "[8,   301] loss: 2.367\n",
      "[8,   601] loss: 2.367\n",
      "[8,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [03:39<00:52, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,     1] loss: 0.008\n",
      "[9,   301] loss: 2.367\n",
      "[9,   601] loss: 2.368\n",
      "[9,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [04:04<00:25, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,     1] loss: 0.008\n",
      "[10,   301] loss: 2.368\n",
      "[10,   601] loss: 2.367\n",
      "[10,   901] loss: 2.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:28<00:00, 26.82s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(10)):  \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for i, data1 in enumerate(train_loader, 0):\n",
    "        data1 = pd.DataFrame(np.array(data1))\n",
    "        data1.dropna()\n",
    "        inputs = torch.tensor(np.array(data1[[0, 1, 2]])).type(torch.LongTensor)\n",
    "        labels = torch.tensor(np.array(data1[3])).type(torch.LongTensor)\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net2(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = Net(3, 10)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = net3.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.008\n",
      "[1,   301] loss: 2.304\n",
      "[1,   601] loss: 2.304\n",
      "[1,   901] loss: 2.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:27<01:49, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.008\n",
      "[2,   301] loss: 2.305\n",
      "[2,   601] loss: 2.304\n",
      "[2,   901] loss: 2.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:55<01:23, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,     1] loss: 0.008\n",
      "[3,   301] loss: 2.305\n",
      "[3,   601] loss: 2.305\n",
      "[3,   901] loss: 2.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [01:27<00:57, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,     1] loss: 0.008\n",
      "[4,   301] loss: 2.305\n",
      "[4,   601] loss: 2.305\n",
      "[4,   901] loss: 2.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [01:55<00:28, 28.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,     1] loss: 0.008\n",
      "[5,   301] loss: 2.304\n",
      "[5,   601] loss: 2.305\n",
      "[5,   901] loss: 2.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:22<00:00, 28.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(5)):  \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for i, data1 in enumerate(train_loader, 0):\n",
    "        data1 = pd.DataFrame(np.array(data1))\n",
    "        data1.dropna()\n",
    "        inputs = torch.tensor(np.array(data1[[0, 1, 2]])).type(torch.LongTensor)\n",
    "        labels = torch.tensor(np.array(data1[3])).type(torch.LongTensor)\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net3(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "замечу что всес 3 сетям не нужно 10 эпох, и после ыторой они loss перестает падать, лучше всего сошлась SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

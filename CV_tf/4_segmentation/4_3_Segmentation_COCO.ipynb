{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"4_3_Segmentation_COCO.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-mYY42BSBOi1","colab_type":"text"},"source":["# Семантическая Сегментация. Часть 3."]},{"cell_type":"markdown","metadata":{"id":"ty18tSuABT9X","colab_type":"text"},"source":["## Переключение версии TensorFlow"]},{"cell_type":"code","metadata":{"id":"fS42SrF5Tm4H","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zvoeKMnP0V7j","colab":{}},"source":["import os\n","import skimage.io as io\n","import numpy as np\n","\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-rSwyWz-BU9t","colab_type":"text"},"source":["## Загрузка датасета COCO и COCO API"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H306Fzq_0Mzi","colab":{}},"source":["if 1:\n","    !mkdir -p data\n","\n","    # !cd data && wget http://images.cocodataset.org/zips/train2017.zip \n","    # !cd data && wget http://images.cocodataset.org/zips/val2017.zip \n","    !cd data && wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip \n","\n","    # !cd data && unzip -q train2017.zip\n","    # !cd data && unzip -q val2017.zip\n","    !cd data && unzip -q annotations_trainval2017.zip\n","\n","    !cd data && git clone https://github.com/cocodataset/cocoapi\n","    !cd data/cocoapi/PythonAPI && make"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y0xB9xnQBbV2","colab_type":"text"},"source":["## Подготовка COCO API"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FLYZPXQg1m94","colab":{}},"source":["COCO_ROOT = './data/'\n","import sys\n","sys.path.insert(0, os.path.join(COCO_ROOT, 'cocoapi/PythonAPI'))\n","from pycocotools.coco import COCO"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0yLcNgZOBgQ0","colab_type":"text"},"source":["## Универсальный класс Dataset для сегментации"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bZhpoFlh1rmE","colab":{}},"source":["class Dataset():\n","\n","    def crop_images(self, img, inp_size, random_crop=False):\n","        shape = tf.shape(img)\n","        pad = (\n","            [0, tf.maximum(inp_size - shape[0], 0)],\n","            [0, tf.maximum(inp_size - shape[1], 0)],\n","            [0, 0],\n","        )\n","        img = tf.pad(img, pad)\n","\n","        if random_crop:\n","            img = tf.image.random_crop(img, (inp_size, inp_size, shape[2]))\n","        else: # central crop\n","            shape = tf.shape(img)\n","            ho = (shape[0] - inp_size) // 2\n","            wo = (shape[1] - inp_size) // 2\n","            img = img[ho:ho+inp_size, wo:wo+inp_size, :]\n","\n","        return img\n","\n","    def train_dataset(self, batch_size, epochs, inp_size):\n","\n","        def item_to_images(item):\n","            random_crop = True\n","            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n","            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n","\n","            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n","            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n","            return img, mask_class\n","\n","        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n","        dataset = dataset.shuffle(buffer_size=len(self.img_list))\n","        dataset = dataset.map(item_to_images)\n","        dataset = dataset.repeat(epochs)\n","        dataset = dataset.batch(batch_size, drop_remainder=True)\n","\n","        return dataset\n","\n","    def val_dataset(self, batch_size, inp_size):\n","\n","        def item_to_images(item):\n","            random_crop = False\n","            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n","            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n","\n","            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n","            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n","            return img, mask_class\n","\n","        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n","        dataset = dataset.map(item_to_images)\n","        dataset = dataset.batch(batch_size, drop_remainder=True)\n","\n","        return dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPXZGUhHBn3Q","colab_type":"text"},"source":["## Класс для сегментационного датасета COCO\n","Класс наследутся от универсльного `Dataset` и реализует кастомную функцию чтения данных."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MjYwt86l1xMt","colab":{}},"source":["class COCO_Dataset(Dataset):\n","\n","    def __init__(self, sublist):\n","        ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_'+sublist+'2017.json')\n","        self.coco = COCO(ann_file_fpath)\n","        self.cat_ids = self.coco.getCatIds(catNms=['person'])\n","        self.img_list = self.coco.getImgIds(catIds=self.cat_ids)\n","\n","    def read_images(self, img_id):\n","        img_id = int(img_id.numpy())\n","        img_data = self.coco.loadImgs(img_id)[0]\n","        img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n","\n","        img = io.imread(os.path.join(COCO_ROOT, img_fname))\n","        if len(img.shape) == 2:\n","            img = np.tile(img[..., None], (1, 1, 3))\n","\n","        ann_ids = self.coco.getAnnIds(imgIds=img_data['id'], catIds=self.cat_ids, iscrowd=None)\n","        anns = self.coco.loadAnns(ann_ids)\n","        mask_class = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n","        for i in range(len(anns)):\n","            mask_class += self.coco.annToMask(anns[i])\n","        mask_class = (mask_class > 0).astype(np.uint8)\n","\n","        img_combined = np.concatenate([img, mask_class[..., None]], axis=2)\n","\n","        return img_combined"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cdevykTc1zWz","colab":{}},"source":["COCO_dataset_train = COCO_Dataset('train')\n","COCO_dataset_val = COCO_Dataset('val')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1c-9GNjZJiAd","colab_type":"code","colab":{}},"source":["# train_ds = COCO_dataset_train.train_dataset(...)\n","# val_ds = COCO_dataset_val.val_dataset(...)"],"execution_count":0,"outputs":[]}]}